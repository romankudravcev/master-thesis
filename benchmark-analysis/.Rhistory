cat("  Calculating downtime from JSON data:\n")
downtime_seconds <- calculate_downtime_from_json(data)
# Return single run result
return(data.frame(
Successful_GET = successful_gets,
Successful_POST = successful_posts,
Failed_GET = failed_gets,
Failed_POST = failed_posts,
Availability = availability,
Message_Lost_Rate = message_lost_rate,
Response_Time_GET = avg_response_time_get,
Response_Time_POST = avg_response_time_post,
Downtime_Seconds = downtime_seconds,
stringsAsFactors = FALSE
))
}, error = function(e) {
cat("✗ Error processing file", basename(file_path), ":", e$message, "\n")
return(NULL)
})
}
# Helper function for null coalescing
`%||%` <- function(x, y) if(is.null(x)) y else x
# ============================================================
# Function to create a missing scenario row with "--" values
# ============================================================
create_missing_scenario <- function(db, db_type, conn_tool, reroute_tool) {
forwarding_tool <- ifelse(reroute_tool == "selected_tool",
names(conn_labels)[conn_labels == conn_tool],
"Clustershift")
return(data.frame(
Connectivity_Tool = conn_tool,
Database = db,
Deployment = db_type,
Forwarding_Tool = forwarding_tool,
Successful_GET_mean = NA,
Successful_GET_sd = NA,
Successful_POST_mean = NA,
Successful_POST_sd = NA,
Failed_GET_mean = NA,
Failed_GET_sd = NA,
Failed_POST_mean = NA,
Failed_POST_sd = NA,
Availability_mean = NA,
Availability_sd = NA,
Message_Lost_Rate_mean = NA,
Message_Lost_Rate_sd = NA,
Response_Time_GET_mean = NA,
Response_Time_GET_sd = NA,
Response_Time_POST_mean = NA,
Response_Time_POST_sd = NA,
Migration_Time_mean = NA,
Migration_Time_sd = NA,
Downtime_mean = NA,
Downtime_sd = NA,
stringsAsFactors = FALSE
))
}
# ============================================================
# Function to process exactly 3 runs and calculate mean + std dev
# ============================================================
process_scenario <- function(db, db_type, conn_tool, reroute_tool) {
if(conn_tool == "skupper" && db == "postgres" && db_type == "stateful") {
cat("Processing:", conn_tool, db, db_type, "→ MISSING DATA (adding -- values)\n")
return(create_missing_scenario(db, db_type, conn_tool, reroute_tool))
}
file_paths <- get_benchmark_files(db, db_type, conn_tool, reroute_tool)
log_paths <- get_log_files(db, db_type, conn_tool, reroute_tool)
forwarding_tool <- ifelse(reroute_tool == "selected_tool",
names(conn_labels)[conn_labels == conn_tool],
"Clustershift")
cat("Processing:", conn_tool, db, db_type, forwarding_tool, "\n")
run_results <- list()
migration_times <- c()
for(i in 1:3) {
cat("  Processing run", i, ":", basename(file_paths[i]), "\n")
result <- process_benchmark_file(file_paths[i])
if(!is.null(result)) {
run_results[[i]] <- result
} else {
cat("  Missing run", i, "for", conn_tool, db, db_type, forwarding_tool, "\n")
}
cat("  Processing log file", i, ":", basename(log_paths[i]), "\n")
migration_time <- parse_migration_time(log_paths[i])
migration_times[i] <- migration_time
}
if(length(run_results) == 3) {
combined_df <- bind_rows(run_results)
summary_result <- combined_df %>%
summarise(
Connectivity_Tool = conn_tool,
Database = db,
Deployment = db_type,
Forwarding_Tool = forwarding_tool,
Successful_GET_mean = round(mean(Successful_GET), 1),
Successful_GET_sd = round(sd(Successful_GET), 2),
Successful_POST_mean = round(mean(Successful_POST), 1),
Successful_POST_sd = round(sd(Successful_POST), 2),
Failed_GET_mean = round(mean(Failed_GET), 1),
Failed_GET_sd = round(sd(Failed_GET), 2),
Failed_POST_mean = round(mean(Failed_POST), 1),
Failed_POST_sd = round(sd(Failed_POST), 2),
Availability_mean = round(mean(Availability), 2),
Availability_sd = round(sd(Availability), 2),
Message_Lost_Rate_mean = round(mean(Message_Lost_Rate), 2),
Message_Lost_Rate_sd = round(sd(Message_Lost_Rate), 2),
Response_Time_GET_mean = round(mean(Response_Time_GET, na.rm = TRUE), 2),
Response_Time_GET_sd = round(sd(Response_Time_GET, na.rm = TRUE), 2),
Response_Time_POST_mean = round(mean(Response_Time_POST, na.rm = TRUE), 2),
Response_Time_POST_sd = round(sd(Response_Time_POST, na.rm = TRUE), 2),
Migration_Time_mean = round(mean(migration_times, na.rm = TRUE), 2),
Migration_Time_sd = round(sd(migration_times, na.rm = TRUE), 2),
Downtime_mean = round(mean(Downtime_Seconds, na.rm = TRUE), 2),
Downtime_sd = round(sd(Downtime_Seconds, na.rm = TRUE), 2),
.groups = "drop"
)
cat("✓ Processed 3 runs successfully\n")
cat("  Migration Time:", summary_result$Migration_Time_mean, "±", summary_result$Migration_Time_sd, "seconds\n")
cat("  Downtime:", summary_result$Downtime_mean, "±", summary_result$Downtime_sd, "seconds\n")
return(summary_result)
} else {
cat("✗ Need exactly 3 runs, found", length(run_results), "→ SKIPPING\n")
return(NULL)
}
}
# ============================================================
# Main processing function
# ============================================================
process_all_benchmarks <- function() {
cat("=== PROCESSING ALL BENCHMARK SCENARIOS WITH WORKING STRUCTURE ===\n")
cat("Date:", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\n")
cat("Base path:", base_path, "\n")
cat("WORKING: Handles both flattened and preserved JSON structures\n")
cat("WORKING: Uses estimation for downtime when detailed data unavailable\n")
cat("CORRECTED: Message loss calculation subtracts 1000 initial entries from server count\n")
cat("CORRECTED: Migration time calculated from log files\n\n")
all_results <- data.frame()
for(conn_tool in connectivity_tools) {
for(db in databases) {
for(db_type in db_types) {
for(reroute_tool in reroute_tools) {
result <- process_scenario(db, db_type, conn_tool, reroute_tool)
if(!is.null(result)) {
all_results <- rbind(all_results, result)
}
}
}
}
}
return(all_results)
}
# ============================================================
# Function to create formatted values with mean ± std dev
# ============================================================
format_value_with_std <- function(mean_vals, sd_vals, unit = "") {
result <- character(length(mean_vals))
for(i in 1:length(mean_vals)) {
mean_val <- mean_vals[i]
sd_val <- sd_vals[i]
if(is.na(mean_val)) {
result[i] <- "--"
} else if(is.na(sd_val) || sd_val == 0) {
result[i] <- paste0(mean_val, unit)
} else {
result[i] <- paste0(mean_val, " ± ", sd_val, unit)
}
}
return(result)
}
# ============================================================
# LaTeX table generation
# ============================================================
generate_complete_latex_table <- function(results_df, output_file = "benchmark_results_complete_working.tex") {
if(!dir.exists(output_path)) {
dir.create(output_path, recursive = TRUE)
}
full_output_path <- file.path(output_path, output_file)
results_df <- results_df %>%
mutate(
Successful_GET_formatted = format_value_with_std(Successful_GET_mean, Successful_GET_sd),
Successful_POST_formatted = format_value_with_std(Successful_POST_mean, Successful_POST_sd),
Failed_GET_formatted = format_value_with_std(Failed_GET_mean, Failed_GET_sd),
Failed_POST_formatted = format_value_with_std(Failed_POST_mean, Failed_POST_sd),
Availability_formatted = format_value_with_std(Availability_mean, Availability_sd, "\\%"),
Migration_Time_formatted = format_value_with_std(Migration_Time_mean, Migration_Time_sd, " s"),
Downtime_formatted = format_value_with_std(Downtime_mean, Downtime_sd, " s")
)
results_df <- results_df %>%
arrange(match(Connectivity_Tool, connectivity_tools),
match(Database, databases),
match(Deployment, db_types),
Forwarding_Tool)
sink(full_output_path)
cat("\\begin{table}[tb]\n")
cat("  \\caption{Benchmark Results: Request Counts, Availability, Migration Time and Downtime}\n")
cat("  \\label{tab:benchmark_results_complete_working}\n")
cat("  \\resizebox{\\linewidth}{!}{%\n")
cat("    \\begin{tabular}{@{}lll l cccc ccc@{}}\n")
cat("      \\toprule\n")
cat("      \\multirow{2}{*}{\\textbf{Connectivity Tool}} & \\multirow{2}{*}{\\textbf{Database}} & \\multirow{2}{*}{\\textbf{Deployment}} & \\multirow{2}{*}{\\textbf{Forwarding Tool}} \n")
cat("        & \\multicolumn{4}{c}{\\textbf{Request Counts}} & \\multicolumn{3}{c}{\\textbf{Performance Metrics}} \\\\\n")
cat("      \\cmidrule(lr){5-8} \\cmidrule(lr){9-11}\n")
cat("        &  &  &  & \\textbf{Successful} & \\textbf{Successful} & \\textbf{Failed} & \\textbf{Failed} & \\textbf{Availability} & \\textbf{Migration} & \\textbf{Downtime} \\\\\n")
cat("        &  &  &  & \\textbf{GET} & \\textbf{POST} & \\textbf{GET} & \\textbf{POST} & \\textbf{(\\%)} & \\textbf{Time (s)} & \\textbf{(s)} \\\\\n")
cat("      \\midrule\n\n")
current_connectivity <- ""
current_database <- ""
for(i in 1:nrow(results_df)) {
row <- results_df[i, ]
conn_display <- names(conn_labels)[conn_labels == row$Connectivity_Tool]
db_display <- names(db_labels)[db_labels == row$Database]
deploy_display <- names(type_labels)[type_labels == row$Deployment]
conn_rows <- results_df %>% filter(Connectivity_Tool == row$Connectivity_Tool) %>% nrow()
db_rows <- results_df %>% filter(Connectivity_Tool == row$Connectivity_Tool, Database == row$Database) %>% nrow()
if(current_connectivity != row$Connectivity_Tool) {
cat("      \\multirow{", conn_rows, "}{*}{", conn_display, "}\n", sep = "")
current_connectivity <- row$Connectivity_Tool
current_database <- ""
} else {
cat("      ")
}
if(current_database != row$Database) {
cat("        & \\multirow{", db_rows, "}{*}{", db_display, "}\n", sep = "")
current_database <- row$Database
} else {
cat("        &                                   ")
}
cat("          & ", deploy_display, "    & ", row$Forwarding_Tool, " & ",
row$Successful_GET_formatted, " & ",
row$Successful_POST_formatted, " & ",
row$Failed_GET_formatted, " & ",
row$Failed_POST_formatted, " & ",
row$Availability_formatted, " & ",
row$Migration_Time_formatted, " & ",
row$Downtime_formatted, " \\\\\n", sep = "")
next_row_exists <- i < nrow(results_df)
if(next_row_exists) {
next_row <- results_df[i + 1, ]
if(row$Connectivity_Tool == next_row$Connectivity_Tool &&
row$Database != next_row$Database) {
cat("        \\cmidrule(lr){2-11}\n")
}
}
if(next_row_exists) {
next_row <- results_df[i + 1, ]
if(row$Connectivity_Tool != next_row$Connectivity_Tool) {
cat("      \\midrule\n\n")
}
}
}
cat("      \\bottomrule\n")
cat("    \\end{tabular}\n")
cat("  }\n")
cat("\\end{table}\n")
sink()
cat("✓ Complete LaTeX table written to:", full_output_path, "\n")
}
# ============================================================
# Function to generate slim response time table (A4 friendly)
# ============================================================
generate_slim_response_time_table <- function(results_df, output_file = "response_time_table_slim.tex") {
if(!dir.exists(output_path)) {
dir.create(output_path, recursive = TRUE)
}
full_output_path <- file.path(output_path, output_file)
# Prepare the data with formatted response times
results_df <- results_df %>%
mutate(
Response_Time_GET_formatted = format_value_with_std(Response_Time_GET_mean, Response_Time_GET_sd, " ms"),
Response_Time_POST_formatted = format_value_with_std(Response_Time_POST_mean, Response_Time_POST_sd, " ms")
) %>%
arrange(match(Connectivity_Tool, connectivity_tools),
match(Database, databases),
match(Deployment, db_types),
Forwarding_Tool)
# Create scenario identifiers
results_df <- results_df %>%
mutate(
Connectivity_Display = case_when(
Connectivity_Tool == "submariner" ~ "Submariner",
Connectivity_Tool == "linkerd" ~ "Linkerd",
Connectivity_Tool == "skupper" ~ "Skupper",
TRUE ~ Connectivity_Tool
),
Database_Display = case_when(
Database == "postgres" ~ "PostgreSQL",
Database == "mongo" ~ "MongoDB",
TRUE ~ Database
),
Deployment_Display = case_when(
Deployment == "operator" ~ "Operator",
Deployment == "stateful" ~ "StatefulSet",
TRUE ~ Deployment
),
Scenario = paste(Connectivity_Display, Database_Display, Deployment_Display, Forwarding_Tool, sep = " + ")
)
sink(full_output_path)
cat("\\begin{table}[tb]\n")
cat("  \\caption{Response Time Comparison Across Connectivity Tools and Configurations}\n")
cat("  \\label{tab:response_time_comparison}\n")
cat("  \\centering\n")
cat("  \\resizebox{\\linewidth}{!}{%\n")
cat("    \\begin{tabular}{@{}l", rep("c", nrow(results_df)), "@{}}\n", sep = "")
cat("      \\toprule\n")
# Header row with scenario names (rotated for space)
cat("      \\textbf{Request Type}")
for(i in 1:nrow(results_df)) {
scenario_parts <- strsplit(results_df$Scenario[i], " \\+ ")[[1]]
# Create a shorter identifier
short_scenario <- paste0(
substr(scenario_parts[1], 1, 3), # First 3 letters of connectivity tool
"-",
substr(scenario_parts[2], 1, 4), # First 4 letters of database
"-",
substr(scenario_parts[3], 1, 3), # First 3 letters of deployment
"-",
substr(scenario_parts[4], 1, 4)  # First 4 letters of forwarding tool
)
cat(" & \\rotatebox{45}{\\textbf{", short_scenario, "}}", sep = "")
}
cat(" \\\\\n")
# Add a second header row with full scenario descriptions in smaller font
cat("      ")
for(i in 1:nrow(results_df)) {
if(i == 1) cat(" & ")
else cat(" & ")
cat("\\tiny{", gsub(" \\+ ", "+", results_df$Scenario[i]), "}", sep = "")
}
cat(" \\\\\n")
cat("      \\midrule\n")
# GET request row
cat("      \\textbf{GET Requests (ms)}")
for(i in 1:nrow(results_df)) {
cat(" & ", results_df$Response_Time_GET_formatted[i], sep = "")
}
cat(" \\\\\n")
# POST request row
cat("      \\textbf{POST Requests (ms)}")
for(i in 1:nrow(results_df)) {
cat(" & ", results_df$Response_Time_POST_formatted[i], sep = "")
}
cat(" \\\\\n")
cat("      \\bottomrule\n")
cat("    \\end{tabular}\n")
cat("  }\n")
cat("  \\begin{tablenotes}\n")
cat("    \\small\n")
cat("    \\item Note: Values shown as mean ± standard deviation across 3 runs. \"--\" indicates missing data.\n")
cat("    \\item Abbreviations: Sub=Submariner, Link=Linkerd, Sku=Skupper, Post=PostgreSQL, Mong=MongoDB, Ope=Operator, Sta=StatefulSet, Clus=Clustershift\n")
cat("  \\end{tablenotes}\n")
cat("\\end{table}\n")
sink()
cat("✓ Slim response time table written to:", full_output_path, "\n")
}
# ============================================================
# Alternative: Vertical layout for even better A4 fit
# ============================================================
generate_vertical_response_time_table <- function(results_df, output_file = "response_time_table_vertical.tex") {
if(!dir.exists(output_path)) {
dir.create(output_path, recursive = TRUE)
}
full_output_path <- file.path(output_path, output_file)
# Prepare the data
results_df <- results_df %>%
mutate(
Response_Time_GET_formatted = format_value_with_std(Response_Time_GET_mean, Response_Time_GET_sd, " ms"),
Response_Time_POST_formatted = format_value_with_std(Response_Time_POST_mean, Response_Time_POST_sd, " ms")
) %>%
arrange(match(Connectivity_Tool, connectivity_tools),
match(Database, databases),
match(Deployment, db_types),
Forwarding_Tool)
# Create display names
results_df <- results_df %>%
mutate(
Connectivity_Display = case_when(
Connectivity_Tool == "submariner" ~ "Submariner",
Connectivity_Tool == "linkerd" ~ "Linkerd",
Connectivity_Tool == "skupper" ~ "Skupper",
TRUE ~ Connectivity_Tool
),
Database_Display = case_when(
Database == "postgres" ~ "PostgreSQL",
Database == "mongo" ~ "MongoDB",
TRUE ~ Database
),
Deployment_Display = case_when(
Deployment == "operator" ~ "Operator",
Deployment == "stateful" ~ "StatefulSet",
TRUE ~ Deployment
)
)
sink(full_output_path)
cat("\\begin{table}[tb]\n")
cat("  \\caption{Response Time Analysis by Configuration and Request Type}\n")
cat("  \\label{tab:response_time_vertical}\n")
cat("  \\centering\n")
cat("  \\begin{tabular}{@{}llllcc@{}}\n")
cat("    \\toprule\n")
cat("    \\textbf{Connectivity} & \\textbf{Database} & \\textbf{Deployment} & \\textbf{Forwarding} & \\textbf{GET Response} & \\textbf{POST Response} \\\\\n")
cat("    \\textbf{Tool} & & \\textbf{Type} & \\textbf{Tool} & \\textbf{Time (ms)} & \\textbf{Time (ms)} \\\\\n")
cat("    \\midrule\n")
current_connectivity <- ""
current_database <- ""
for(i in 1:nrow(results_df)) {
row <- results_df[i, ]
# Calculate multirow spans
conn_rows <- results_df %>% filter(Connectivity_Tool == row$Connectivity_Tool) %>% nrow()
db_rows <- results_df %>% filter(Connectivity_Tool == row$Connectivity_Tool, Database == row$Database) %>% nrow()
# Connectivity tool column (with multirow)
if(current_connectivity != row$Connectivity_Tool) {
cat("    \\multirow{", conn_rows, "}{*}{", row$Connectivity_Display, "}", sep = "")
current_connectivity <- row$Connectivity_Tool
current_database <- ""
} else {
cat("    ")
}
# Database column (with multirow)
if(current_database != row$Database) {
cat(" & \\multirow{", db_rows, "}{*}{", row$Database_Display, "}", sep = "")
current_database <- row$Database
} else {
cat(" & ")
}
# Deployment, Forwarding, and Response times
cat(" & ", row$Deployment_Display,
" & ", row$Forwarding_Tool,
" & ", row$Response_Time_GET_formatted,
" & ", row$Response_Time_POST_formatted, " \\\\\n", sep = "")
# Add cmidrule between different databases within same connectivity tool
next_row_exists <- i < nrow(results_df)
if(next_row_exists) {
next_row <- results_df[i + 1, ]
if(row$Connectivity_Tool == next_row$Connectivity_Tool &&
row$Database != next_row$Database) {
cat("    \\cmidrule(lr){2-6}\n")
}
}
# Add midrule between different connectivity tools
if(next_row_exists) {
next_row <- results_df[i + 1, ]
if(row$Connectivity_Tool != next_row$Connectivity_Tool) {
cat("    \\midrule\n")
}
}
}
cat("    \\bottomrule\n")
cat("  \\end{tabular}\n")
cat("  \\begin{tablenotes}\n")
cat("    \\small\n")
cat("    \\item Note: Response times shown as mean ± standard deviation across 3 experimental runs.\n")
cat("    \\item \"--\" indicates scenarios where data collection was incomplete.\n")
cat("  \\end{tablenotes}\n")
cat("\\end{table}\n")
sink()
cat("✓ Vertical response time table written to:", full_output_path, "\n")
}
# ============================================================
# Main execution
# ============================================================
cat("=== BENCHMARK ANALYSIS WITH WORKING JSON STRUCTURE HANDLING ===\n")
cat("Current Date and Time (UTC - YYYY-MM-DD HH:MM:SS formatted): 2025-08-22 08:27:45\n")
cat("Current User's Login: romankudravcev\n")
cat("Base path:", base_path, "\n")
cat("Output path:", output_path, "\n")
cat("WORKING: Handles the actual JSON structure we're getting from jsonlite\n")
cat("WORKING: Uses estimation for downtime when detailed success/failure data unavailable\n\n")
# Process all benchmark files
results <- process_all_benchmarks()
# Display and save results
if(nrow(results) > 0) {
cat("\n=== FINAL RESULTS WITH WORKING STRUCTURE HANDLING ===\n")
cat("Total scenarios processed:", nrow(results), "\n")
complete_scenarios <- sum(!is.na(results$Availability_mean))
missing_scenarios <- sum(is.na(results$Availability_mean))
cat("Complete scenarios (with 3 runs):", complete_scenarios, "\n")
cat("Missing scenarios (with '--' values):", missing_scenarios, "\n\n")
cat("\n=== GENERATING SLIM RESPONSE TIME TABLES ===\n")
generate_slim_response_time_table(results)
generate_vertical_response_time_table(results)
cat("=== MIGRATION TIME AND DOWNTIME SUMMARY ===\n")
timing_data <- results %>%
filter(!is.na(Migration_Time_mean) | !is.na(Downtime_mean)) %>%
select(Connectivity_Tool, Database, Deployment, Forwarding_Tool,
Migration_Time_mean, Migration_Time_sd, Downtime_mean, Downtime_sd) %>%
arrange(Downtime_mean)
if(nrow(timing_data) > 0) {
print(timing_data)
migration_data <- timing_data[!is.na(timing_data$Migration_Time_mean), ]
if(nrow(migration_data) > 0) {
cat("\nMigration time range:", min(migration_data$Migration_Time_mean), "s to",
max(migration_data$Migration_Time_mean), "s\n")
cat("Average migration time:", round(mean(migration_data$Migration_Time_mean), 2), "s\n")
}
downtime_data <- timing_data[!is.na(timing_data$Downtime_mean), ]
if(nrow(downtime_data) > 0) {
cat("Downtime range:", min(downtime_data$Downtime_mean), "s to",
max(downtime_data$Downtime_mean), "s\n")
cat("Average downtime:", round(mean(downtime_data$Downtime_mean), 2), "s\n")
} else {
cat("No downtime data calculated\n")
}
} else {
cat("No timing data found!\n")
}
generate_complete_latex_table(results)
csv_path <- file.path(output_path, "benchmark_results_working.csv")
write.csv(results, csv_path, row.names = FALSE)
cat("✓ Complete results saved as CSV:", csv_path, "\n")
} else {
cat("\n✗ No results found.\n")
}
cat("\nAnalysis complete with working structure handling! 📊\n")
